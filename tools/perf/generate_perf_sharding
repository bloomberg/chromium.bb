#!/usr/bin/env vpython
# Copyright 2018 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

import argparse
import json
import multiprocessing
import sys

from core import benchmark_utils
from core import bot_platforms
from core import sharding_map_generator
from core import retrieve_story_timing


def get_parser():
  parser = argparse.ArgumentParser(
      description='Generate perf test sharding map.')
  parser.add_argument(
      '--regenerate-timing-data', '-r', action='store_true',
      help=('Whether to regenerate timing data for all builders in '
            'chromium.perf'), default=False)

  parser.add_argument(
      '--builder', '-b', action='store', nargs='*',
      help=('The builder name to reshard. If not specified, use all '
            'perf builders'),
      choices=bot_platforms.ALL_PLATFORM_NAMES)
  return parser


def _GenerateBenchmarksToShardsList(benchmarks):
  """ Return |benchmarks_to_shard| from given list of |benchmarks|.
    benchmarks_to_shard is a list all benchmarks to be sharded. Its
    structure is as follows:
    [{
       "name": "benchmark_1",
       "stories": [ "storyA", "storyB",...],
       "repeat": <number of pageset_repeat>
      },
      {
       "name": "benchmark_2",
       "stories": [ "storyA", "storyB",...],
       "repeat": <number of pageset_repeat>
      },
       ...
    ]

    The "stories" field contains a list of ordered story names. Notes that
    this should match the actual order of how the benchmark stories are
    executed for the sharding algorithm to be effective.
  """
  benchmarks_to_shard = []
  for b in benchmarks:
    benchmarks_to_shard.append({
        'name': b.Name(),
        'repeat':  b().options.get('pageset_repeat', 1),
        'stories': benchmark_utils.GetBenchmarkStoryNames(b())
    })
  return benchmarks_to_shard


def _LoadTimingData(args):
  builder_name, timing_file_path = args
  data = retrieve_story_timing.FetchAverageStortyTimingData(
           configurations=[builder_name], num_last_days=5)
  with open(timing_file_path, 'w') as output_file:
    json.dump(data, output_file, indent=4, separators=(',', ': '))
  print 'Finish retrieve story timing data for %s' % repr(builder_name)


def _UpdateShardsForBuilders(builder_names, regenerate_timing_data):

  builders = {b for b in bot_platforms.ALL_PLATFORMS if b.name in builder_names}

  if regenerate_timing_data:
    print 'Update shards timing data. May take a while...'
    args = []
    for b in builders:
      args.append((b.name, b.timing_file_path))
    p = multiprocessing.Pool(len(args))
    p.map(_LoadTimingData, args)

  for b in builders:
    with open(b.timing_file_path) as f:
      timing_data = json.load(f)
    benchmarks_to_shard = _GenerateBenchmarksToShardsList(b.benchmarks_to_run)
    sharding_map = sharding_map_generator.generate_sharding_map(
        benchmarks_to_shard, timing_data, num_shards=b.num_shards,
        debug=False)
    with open(b.shards_map_file_path, 'w') as output_file:
      json.dump(sharding_map, output_file, indent=4, separators=(',', ': '))
    print 'Updated sharding map for %s' % repr(b.name)


def main():
  parser = get_parser()
  options = parser.parse_args()
  builder_names = options.builder or bot_platforms.ALL_PLATFORM_NAMES
  _UpdateShardsForBuilders(
      builder_names, options.regenerate_timing_data)



if __name__ == '__main__':
  sys.exit(main())
