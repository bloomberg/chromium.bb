path: "tensorflow.keras.preprocessing.text"
tf_module {
  member {
    name: "Tokenizer"
    mtype: "<type \'type\'>"
  }
  member_method {
    name: "hashing_trick"
    argspec: "args=[\'text\', \'n\', \'hash_function\', \'filters\', \'lower\', \'split\'], varargs=None, keywords=None, defaults=[\'None\', \'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\', \'True\', \' \'], "
  }
  member_method {
    name: "one_hot"
    argspec: "args=[\'input_text\', \'n\', \'filters\', \'lower\', \'split\'], varargs=None, keywords=None, defaults=[\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\', \'True\', \' \'], "
  }
  member_method {
    name: "text_to_word_sequence"
    argspec: "args=[\'input_text\', \'filters\', \'lower\', \'split\'], varargs=None, keywords=None, defaults=[\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\', \'True\', \' \'], "
  }
  member_method {
    name: "tokenizer_from_json"
    argspec: "args=[\'json_string\'], varargs=None, keywords=None, defaults=None"
  }
}
