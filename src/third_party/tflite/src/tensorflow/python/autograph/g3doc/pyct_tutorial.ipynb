{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fWfkYsCgPvqR"
      },
      "source": [
        "# Short intro to the SCT library of AutoGraph\n",
        "\n",
        "**Work in progress, use with care and expect changes.**\n",
        "\n",
        "The `pyct` module packages the source code transformation APIs used by AutoGraph.\n",
        "\n",
        "This tutorial is just a preview - there is no PIP package yet, and the API has not been finalized, although most of those shown here are quite stable.\n",
        "\n",
        "[Run in Colab](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/pyct_tutorial.ipynb)\n",
        "\n",
        "Requires `tf-nightly`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wq1DRamRlqoB"
      },
      "outputs": [],
      "source": [
        "!pip install tf-nightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r7Q78WIKe2cu"
      },
      "source": [
        "### Writing a custom code generator\n",
        "\n",
        "[transformer.CodeGenerator](https://github.com/tensorflow/tensorflow/blob/40802bcdb5c8a4379da2145441f51051402bd29b/tensorflow/python/autograph/pyct/transformer.py#L480) is an AST visitor that outputs a string. This makes it useful in the final stage of translating Python to another language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HHaCMFOpuoVx"
      },
      "source": [
        "Here's a toy C++ code generator written using a `transformer.CodeGenerator`, which is just a fancy subclass of [ast.NodeVisitor](https://docs.python.org/3/library/ast.html#ast.NodeVisitor):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PJlTIbJlurpm"
      },
      "outputs": [],
      "source": [
        "import gast\n",
        "from tensorflow.python.autograph.pyct import transformer\n",
        "\n",
        "class BasicCppCodegen(transformer.CodeGenerator):\n",
        "\n",
        "  def visit_Name(self, node):\n",
        "    self.emit(node.id)\n",
        "\n",
        "  def visit_arguments(self, node):\n",
        "    self.visit(node.args[0])\n",
        "    for arg in node.args[1:]:\n",
        "      self.emit(', ')\n",
        "      self.visit(arg)\n",
        "\n",
        "  def visit_FunctionDef(self, node):\n",
        "    self.emit('void {}'.format(node.name))\n",
        "    self.emit('(')\n",
        "    self.visit(node.args)\n",
        "    self.emit(') {\\n')\n",
        "    self.visit_block(node.body)\n",
        "    self.emit('\\n}')\n",
        "\n",
        "  def visit_Call(self, node):\n",
        "    self.emit(node.func.id)\n",
        "    self.emit('(')\n",
        "    self.visit(node.args[0])\n",
        "    for arg in node.args[1:]:\n",
        "      self.emit(', ')\n",
        "      self.visit(arg)\n",
        "    self.emit(');')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nUhlScyOjlYM"
      },
      "source": [
        "Let's try it on a simple function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ty9q853QvUqo"
      },
      "outputs": [],
      "source": [
        "def f(x, y):\n",
        "  print(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R8N15UpVvbmu"
      },
      "source": [
        "First, parse the Python code and annotate the AST. This is easily done with standard libraries, but [parser.parse_entity](https://github.com/tensorflow/tensorflow/blob/40802bcdb5c8a4379da2145441f51051402bd29b/tensorflow/python/autograph/pyct/parser.py#L182) makes it a single call. It returns a [gast](https://github.com/serge-sans-paille/gast) AST, so you don't have to worry about Python version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Cs_Ls0MesvBp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import parser\n",
        "\n",
        "node, source = parser.parse_entity(f, ())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kuT7J-xps_2Y"
      },
      "source": [
        "There are a couple of context objects that most transformer objects like `CodeGenerator` use.\n",
        "\n",
        "Of note here is `EntityInfo.namespace`, which contains the runtime values for all the global and closure names that the function has access to. Inside a transformer object, this is available under `self.ctx.info.namespace`.\n",
        "\n",
        "For example, if a function uses NumPy, its namespace will typically include `'np'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pnB63kpttIVU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import inspect_utils\n",
        "\n",
        "f_info = transformer.EntityInfo(\n",
        "    name='f',\n",
        "    source_code=source,\n",
        "    source_file=None,\n",
        "    future_features=(),\n",
        "    namespace=inspect_utils.getnamespace(f))\n",
        "ctx = transformer.Context(f_info, None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kCjcucmiwW98"
      },
      "source": [
        "Finally, it's just a matter of running the generator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SdHjliuuwaaJ"
      },
      "outputs": [],
      "source": [
        "codegen = BasicCppCodegen(ctx)\n",
        "codegen.visit(node)\n",
        "\n",
        "print(codegen.code_buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rmRI9dG_ydE_"
      },
      "source": [
        "### Helpful static analysis passes\n",
        "\n",
        "The `static_analysis` module contains various helper passes for dataflow analyis.\n",
        "\n",
        "All these passes annotate the AST. These annotations can be extracted using [anno.getanno](https://github.com/tensorflow/tensorflow/blob/40802bcdb5c8a4379da2145441f51051402bd29b/tensorflow/python/autograph/pyct/anno.py#L111). Most of them rely on the `qual_names` annotations, which just simplify the way more complex identifiers like `a.b.c` are accessed.\n",
        "\n",
        "The most useful is the activity analysis which just inventories symbols read, modified, etc.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GEJ30Wea4Xfy"
      },
      "outputs": [],
      "source": [
        "def get_node_and_ctx(f):\n",
        "  node, source = parser.parse_entity(f, ())\n",
        "  f_info = transformer.EntityInfo(\n",
        "    name='f',\n",
        "    source_code=source,\n",
        "    source_file=None,\n",
        "    future_features=(),\n",
        "    namespace=None)\n",
        "  ctx = transformer.Context(f_info, None, None)\n",
        "  return node, ctx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BiwPJrDd0aAX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import anno\n",
        "from tensorflow.python.autograph.pyct import qual_names\n",
        "from tensorflow.python.autograph.pyct.static_analysis import annos\n",
        "from tensorflow.python.autograph.pyct.static_analysis import activity\n",
        "\n",
        "\n",
        "def f(a):\n",
        "  b = a + 1\n",
        "  return b\n",
        "\n",
        "\n",
        "node, ctx = get_node_and_ctx(f)\n",
        "\n",
        "node = qual_names.resolve(node)\n",
        "node = activity.resolve(node, ctx)\n",
        "\n",
        "fn_scope = anno.getanno(node, annos.NodeAnno.BODY_SCOPE)  # Note: tag will be changed soon.\n",
        "\n",
        "\n",
        "print('read:', fn_scope.read)\n",
        "print('modified:', fn_scope.modified)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w8dBRlKkFNIP"
      },
      "source": [
        "Another useful utility is the control flow graph builder.\n",
        "\n",
        "Of course, a CFG that fully accounts for all effects is impractical to build in a late-bound language like Python without creating an almost fully-connected graph. However, one can be reasonably built if we ignore the potential for functions to raise arbitrary exceptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KvLe9lWnFg7N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import cfg\n",
        "\n",
        "\n",
        "def f(a):\n",
        "  if a \u003e 0:\n",
        "    return a\n",
        "  b = -a\n",
        "\n",
        "node, ctx = get_node_and_ctx(f)\n",
        "\n",
        "node = qual_names.resolve(node)\n",
        "cfgs = cfg.build(node)\n",
        "cfgs[node]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cro-jfPA2oxR"
      },
      "source": [
        "Other useful analyses include liveness analysis. Note that these make simplifying assumptions, because in general the CFG of a Python program is a graph that's almost complete. The only robust assumption is that execution can't jump backwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "73dARy4_2oAI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import anno\n",
        "from tensorflow.python.autograph.pyct import cfg\n",
        "from tensorflow.python.autograph.pyct import qual_names\n",
        "from tensorflow.python.autograph.pyct.static_analysis import annos\n",
        "from tensorflow.python.autograph.pyct.static_analysis import liveness\n",
        "\n",
        "\n",
        "def f(a):\n",
        "  b = a + 1\n",
        "  return b\n",
        "\n",
        "\n",
        "node, ctx = get_node_and_ctx(f)\n",
        "\n",
        "node = qual_names.resolve(node)\n",
        "cfgs = cfg.build(node)\n",
        "node = activity.resolve(node, ctx)\n",
        "node = liveness.resolve(node, ctx, cfgs)\n",
        "\n",
        "print('live into `b = a + 1`:', anno.getanno(node.body[0], anno.Static.LIVE_VARS_IN))\n",
        "print('live into `return b`:', anno.getanno(node.body[1], anno.Static.LIVE_VARS_IN))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GKSaqLbKQI_v"
      },
      "source": [
        "### Writing a custom Python transpiler\n",
        "\n",
        "`transpiler.FunctionTranspiler` is a generic class for a Python [source-to-source compiler](https://en.wikipedia.org/wiki/Source-to-source_compiler). It operates on Python ASTs. Subclasses override its [transform_ast](https://github.com/tensorflow/tensorflow/blob/95ea3404528afcb1a74dd5f0946ea8d17beda28b/tensorflow/python/autograph/pyct/transpiler.py#L261) method.\n",
        "\n",
        "Unlike the `transformer` module, which have an AST as input/output, the `transpiler` APIs accept and return actual Python objects, handling the tasks associated with parsing, unparsing and loading of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eicHoYlzRhnc"
      },
      "source": [
        "Here's a transpiler that does nothing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "edaG6dWEPvUI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import transpiler\n",
        "\n",
        "\n",
        "class NoopTranspiler(transpiler.FunctionTranspiler):\n",
        "\n",
        "  def transform_ast(self, ast, transformer_context):\n",
        "    return ast\n",
        "\n",
        "tr = NoopTranspiler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hKxmlWeQSQyN"
      },
      "source": [
        "The main method is [transform_function](https://github.com/tensorflow/tensorflow/blob/95ea3404528afcb1a74dd5f0946ea8d17beda28b/tensorflow/python/autograph/pyct/transpiler.py#L384), which as its name suggests, operates on functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HXTIYsunSVr1"
      },
      "outputs": [],
      "source": [
        "def f(x, y):\n",
        "  return x + y\n",
        "\n",
        "\n",
        "new_f, _, _ = tr.transform_function(f, None, None, {})\n",
        "\n",
        "print(new_f(1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aKO42LBXw3SD"
      },
      "source": [
        "### Adding new variables to the transformed code\n",
        "\n",
        "The transformed function has the same global and local variables as the original function. You can of course generate local imports to add any new references into the generated code, but an easier method is to use the `extra_locals` arg of `transform_function`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_Wl0n5I_1NJZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.autograph.pyct import parser\n",
        "\n",
        "\n",
        "class HelloTranspiler(transpiler.FunctionTranspiler):\n",
        "\n",
        "  def transform_ast(self, ast, transformer_context):\n",
        "    print_code = parser.parse('print(\"Hello\", name)')\n",
        "    ast.body = [print_code] + ast.body\n",
        "    return ast\n",
        "\n",
        "\n",
        "def f(x, y):\n",
        "  pass\n",
        "\n",
        "\n",
        "extra_locals = {'name': 'you'}\n",
        "new_f, _, _ = HelloTranspiler().transform_function(f, None, None, extra_locals)\n",
        "\n",
        "_ = new_f(1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JcMSHJXK6pO2"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "print(inspect.getsource(new_f))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pyctr_tutorial.ipynb",
      "provenance": [
        {
          "file_id": "1dT93XRkt7vUpVp7GZech8LB0u1OytKff",
          "timestamp": 1586205976756
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
