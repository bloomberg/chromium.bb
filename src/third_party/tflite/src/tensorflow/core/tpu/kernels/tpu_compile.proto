/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
syntax = "proto3";

package tensorflow.tpu;

import "tensorflow/compiler/tf2xla/host_compute_metadata.proto";
import "tensorflow/compiler/xla/service/hlo.proto";
import "tensorflow/compiler/xla/xla_data.proto";
import "tensorflow/core/framework/tensor.proto";
import "tensorflow/core/framework/tensor_shape.proto";
import "tensorflow/core/framework/types.proto";
import "tensorflow/core/protobuf/tpu/compile_metadata.proto";
import "tensorflow/core/tpu/kernels/tpu_executable_info.proto";

message PerCoreVariableIndices {
  // For each resource variable output, what was the index of the corresponding
  // input and was it updated? The indices are sorted by input order.
  repeated TPUExecutableInfoProto.UpdateIndexPair variable_indices = 1;
}

message PerCoreArgShapes {
  // Argument shapes for each Tpu core.
  repeated xla.ShapeProto shapes = 1;
}

message PerCoreOutputShapes {
  // Output shapes for each Tpu core.
  repeated xla.ShapeProto shapes = 1;
}

message OutputDescriptionProto {
  // Type and shape of the output. The shape is the unflattened shape.
  // When `type` is DT_RESOURCE, `shape` is the shape of the resource
  // variable's value.
  tensorflow.DataType type = 1;
  tensorflow.TensorShapeProto shape = 2;

  // Constant output value, if known to be constant at JIT compilation time.
  // 'Tensor' is in host memory.
  bool is_constant = 3;
  tensorflow.TensorProto constant_value = 4;

  // When this output is a resource, i.e. `type == DT_RESOURCE`, this is
  // the index of the input that contains the resource.
  int32 input_index = 5;

  // Whether this output is a TensorList.
  bool is_tensor_list = 6;
}

// Describes a variable write side effect of the computation.
message ResourceUpdateProto {
  // Index of the input that contains the variable resource to write to.
  int32 input_index = 1;

  // Type and shape of the tensor to be written back.
  // The `shape` field has the same meaning as the Argument::shape field.
  tensorflow.DataType type = 2;
  tensorflow.TensorShapeProto shape = 3;

  // Was the value of the variable modified by the computation?
  // (Always true, unless `return_updated_values_for_all_resources` is true.)
  bool modified = 4;

  // If the resource is a TensorArray, the set of gradients read or written.
  map<string, bool> tensor_array_gradients_accessed = 5;
}

// Describes the result of a XLA Compiler compilation.
message XlaCompilationResultProto {
  // Vector that maps from the parameters of the XLA computation to their
  // original argument positions. To handle compile-time constant inputs, the
  // parameters to the XLA computation may be a subset of the original
  // arguments. The relative ordering of parameters are maintained.
  repeated int32 input_mappings = 1;

  // Input shapes of the computation. If we are flattening inputs, these are
  // the flattened shapes.
  repeated xla.ShapeProto xla_input_shapes = 2;

  // Output shape in XLA format. The output shape is always a tuple. If we
  // are flattening outputs, these are the flattened shapes.
  xla.ShapeProto xla_output_shape = 3;

  // TensorFlow shapes of outputs, together with the values of any
  // constant arguments. Vector indexed by Tensorflow _Retval number,
  // containing both constant and non-constant results.
  repeated OutputDescriptionProto outputs = 4;

  // TensorFlow shapes and types of sends/recvs from HostCompute Ops to their
  // matching RecvAtHost/SendFromHost Ops in the outer graph.
  tf2xla.HostComputeMetadata host_compute_metadata = 5;

  // Resources whose values were updated by the computation, ordered
  // by return value position (which is the same as the order the resources
  // were passed as arguments). Resource updates follow the non-constant
  // results in the outputs of XLA computation.
  repeated ResourceUpdateProto resource_updates = 6;

  // The XLA computation built from the tensorflow subgraph.
  xla.HloModuleProto computation = 7;
}

// TpuAotCompilationRequestProto represents a compilation request for performing
// ahead-of-time (AOT) compilation of XLA Computations into XLA HLO IR.
message TpuAotCompilationRequestProto {
  // A set of HLO module built to run concurrently
  // across different devices.
  xla.HloModuleGroupProto hlo_module_group = 1;

  // Compilation metadata.
  TPUCompileMetadataProto metadata = 2;

  // DeviceAssignmentProto is a serialized form of DeviceAssignment class, which
  // represents the device ids assigned to a set of replicated computations.
  // See xla::DeviceAssignment class comment for more details.
  xla.DeviceAssignmentProto device_assignment = 3;

  // Per TPU core program arguments shapes.
  repeated PerCoreArgShapes per_core_arg_shapes = 4;

  // Per TPU core program outputs shapes.
  repeated PerCoreOutputShapes per_core_output_shapes = 5;

  // Per TPU core information containing what was the index of the corresponding
  // input and if whether it was updated. The indices are sorted by input order.
  repeated PerCoreVariableIndices per_core_variable_indices = 6;

  // XLA compiler compilation result.
  XlaCompilationResultProto compilation_result = 7;
}
